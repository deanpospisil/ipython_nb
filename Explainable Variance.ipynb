{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are deciding between two ways of making a comparison between an artifical and biological neural net's responses. The main issue is that one is stochastic and the other is not.\n",
    "\n",
    "Our two options are:\n",
    "* Simulate net units as having neural variability: to make the artificial net noisy by adding a comparable amounts of noise as seen in V4.\n",
    "    * This method entails choosing a neuron like distribution from which to pull net responses.\n",
    "    * We would take the actual responses as the mean of this neuron-like distribution.\n",
    "    * Choosing the shape of the distribution is more difficult.\n",
    "        * Poisson: with Poisson only the mean is needed to parameterize our distribution. An issue with this choice is many units are not all positive in their responses. Another issue is responses of units are not counts. \n",
    "        * Gaussian: Since a sum of Poissons starts to look Gaussian, we could just take the mean and SE to create our distributions. Still choosing the SE would entail many choices, do we take average SE or pull from a few cells? \n",
    "\n",
    "\n",
    "* Inflate the fit of V4: inflate the quality of the fit of V4 commensurate with a measure of its variability (Pasupathy and Conor 2001)\n",
    "    * This method entails making an assumption on the distribution of the mean of responses to each shape. From this we could determine on average how much of the variance of a given draw is owing to the expected value of the selectivity versus variance resulting from the distribution about that expected value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Inflate the fit of V4</h1>\n",
    "\n",
    "The data we will fit is:\n",
    "$$R_i = \\frac{1}{n}\\sum_j^n{r_{ij}}$$\n",
    "\n",
    "Where $j$ indexes the $n$ IID trials of responses to a shape, and $i$ indexes over the $s$ shapes. To begin with we assume the $r$ are $IID$ with $E[r_i]=\\mu_i$ and $Var[r_i] = \\sigma_i^2$ thus:\n",
    "$$\\frac{\\sigma_i^2}{n} = Var[\\frac{1}{n}\\sum_j^n{r_{ij}}]$$\n",
    "\n",
    "Eventually we are going to fit the data with a model $x_i$ and we will measure the quality of that fit by the fraction of the variance accounted for by the model. \n",
    "$$Unexplained \\ Variance = \\frac{\\sum_i^n{ (R_i - ax_i)^2}}{\\sum_i^n{( R_i - \\frac{1}{n} \\sum_i^n{R_i} )^2}}$$\n",
    "\n",
    "\n",
    "$$a = \\frac{R_i \\ x_i}{x_i \\ x_i}$$\n",
    "\n",
    "The numerator here is the error between the least squares fit of the model to the data, and the denominator is the variance of the data. What Pasupathy and Connor do is estimate the fraction of unexplainable variance and subtract it from the unexplained variance.\n",
    "\n",
    "$$True \\ Explained \\ Variance = 1 - (Unexplained \\ Variance - Unexplainable \\ Variance )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the issue we have to deal with is that for $\\sigma>0$ this measure of fit will not go to 1 in expectation. This is because even with a squared error minimizing model $x_i=\\mu_i$ there will be some residual variance left over from sampling variability. Furthermore this residual variance increases with $\\sigma$ thus even if we were fitting the same neural responses but with different $\\sigma$, i.e. greater variability, our fraction of variance accounted for would be systematically biased.\n",
    "\n",
    "One way to account for this is to adjust our denominator so that it reflects the actual fraction of 'explainable variance'. So we would need to determine how much of the variance in the denominator is the result of $\\sigma_i$ then subtract it off. I should not that at the outset this is a bit of a risky proposition, we will not know $\\sigma$ and thus will have to estimate it which is difficult from only a few trials.\n",
    "Lets first determine the value of the denominator in expectation.\n",
    "The facts we will need to do this are:\n",
    "* $E[R_i] = \\mu_i$\n",
    "* $Var[R_i] = \\sigma_i^2$ where $\\sigma_i^2$ was determined from $r_i$\n",
    "* $E[X^2] = Var[X] + E[X]^2$\n",
    "* $E[XY] = E[X]E[Y] \\ \\ (X,Y \\  independent)$\n",
    "\n",
    "\n",
    "$$Var = E[\\sum_i^s{( R_i - \\frac{1}{s} \\sum_g^s{R_g} )^2}]$$\n",
    "\n",
    "$$= \\sum_i^s{E[( R_i - \\frac{1}{s} \\sum_g^s{R_g} )( R_i - \\frac{1}{s} \\sum_g^s{R_g} )}]$$\n",
    "\n",
    "$$= \\sum_i^s{E[R_i^2  - \\frac{2}{s} R_i\\sum_g^s{R_g} + \\frac{1}{s^2} \\sum_g^s{R_g} \\sum_g^s{R_g}]} $$\n",
    "\n",
    "$$= \\sum_i^s{(E[R_i^2]  - \\frac{2}{s} E[R_i\\sum_g^s{R_g}] + \\frac{1}{s^2}E[\\sum_g^s{R_g} \\sum_g^s{R_g}])} $$\n",
    "\n",
    "$$= \\sum_i^s{E[R_i^2]}  - \\frac{2}{s}\\sum_i^s{ E[R_i\\sum_g^s{R_g}]} + \\frac{1}{s^2}\\sum_i^s{E[\\sum_g^s{R_g} \\sum_g^s{R_g}]} $$\n",
    "\n",
    "Now lets look at each of these terms in turn:\n",
    "\n",
    "1) \n",
    "\n",
    "$$\\sum_i^s{E[R_i^2]} $$\n",
    "$$\\sum_i^s{(\\sigma_i^2 + \\mu_i^2)}$$\n",
    "\n",
    "2) \n",
    "\n",
    "$$- \\frac{2}{s}\\sum_i^s{ E[R_i\\sum_g^s{R_g}]} $$\n",
    "$$- \\frac{2}{s}\\sum_i^s{ E[R_i^2 + R_i \\sum_{g \\neq i}^{s-1}{R_g}]} $$\n",
    "$$- \\frac{2}{s}\\sum_i^s{ (\\sigma_i^2 + \\mu_i^2  + \\mu_i \\sum_{g \\neq i}^{s-1}{\\mu_g})} $$\n",
    "$$- \\frac{2}{s}\\sum_i^s{ (\\sigma_i^2  + \\mu_i \\sum_{g}^{s}{\\mu_g})} $$\n",
    "\n",
    "\n",
    "3) \n",
    "\n",
    "$$\\frac{1}{s^2} \\sum_i^s{E[\\sum_g^s{R_g} \\sum_g^s{R_g}]}$$\n",
    "$$\\frac{s}{s^2} \\sum_i^s{(\\sigma_i^2  + \\mu_i \\sum_{g}^{s}{\\mu_g})}$$\n",
    "$$\\frac{1}{s} \\sum_i^s{(\\sigma_i^2  + \\mu_i \\sum_{g}^{s}{\\mu_g})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining these back together:\n",
    "\n",
    "$$Var = \\sum_i^s{(\\sigma_i^2 + \\mu_i^2)} - \\frac{2}{s}\\sum_i^s{ (\\sigma_i^2  + \\mu_i \\sum_{g}^{s}{\\mu_g})}  +  \\frac{1}{s} \\sum_i^s{(\\sigma_i^2  + \\mu_i \\sum_{g}^{s}{\\mu_g})}$$\n",
    "\n",
    "$$= \\sum_i^s{(\\sigma_i^2 + \\mu_i^2)} - \\frac{1}{s}\\sum_i^s{ (\\sigma_i^2  + \\mu_i \\sum_{g}^{s}{\\mu_g})} $$\n",
    "\n",
    "$$= \\sum_i^s{(\\sigma_i^2 + \\mu_i^2)} - \\frac{1}{s}\\sum_i^s{(\\sigma_i^2 + \\mu_i^2  + \\mu_i \\sum_{g \\neq i}^{s-1}{\\mu_g})} $$\n",
    "\n",
    "$$= \\sum_i^s{(\\sigma_i^2 + \\mu_i^2)} - \\frac{1}{s}\\sum_i^s{(\\sigma_i^2 + \\mu_i^2)}  - \\frac{1}{s} \\sum_i^s{(\\mu_i \\sum_{g \\neq i}^{s-1}{\\mu_g})} $$\n",
    "\n",
    "$$= \\frac{s-1}{s}\\sum_i^s{(\\sigma_i^2 + \\mu_i^2)}  - \\frac{1}{s} \\sum_i^s{(\\mu_i \\sum_{g \\neq i}^{s-1}{\\mu_g})} $$\n",
    "\n",
    "$$= \\frac{s-1}{s}\\sum_i^s{\\sigma_i^2} + \\frac{s-1}{s}\\sum_i^s{\\mu_i^2}  - \\frac{1}{s} \\sum_i^s{(\\mu_i \\sum_{g \\neq i}^{s-1}{\\mu_g})} $$\n",
    "\n",
    "With the noise variance accounted for, the method of Pasupathy and Conor amounts to:\n",
    "\n",
    "$$\\frac{\\sum_i^n{ (R_i - ax_i)^2} - \\frac{s-1}{s}\\sum_i^s{\\sigma_i^2}}{Var} $$\n",
    "\n",
    "We will need to estimate $\\sigma^2$ and an unbiased estimator of it is the sample variance:\n",
    "\n",
    "$$\\frac{1}{n-1} \\sum_j^n{(r_{ij} - \\frac{1}{n}\\sum_j^n{r_{ij}})^2} $$\n",
    "\n",
    "dividing this by n gives us the variance of the mean.\n",
    "$$\\frac{1}{n^2-n} \\sum_j^n{(r_{ij} - \\frac{1}{n}\\sum_j^n{r_{ij}})^2} $$\n",
    "\n",
    "Lets try this in simulation and see if it is true in expectation, and the kind of variance we see. \n",
    "First we want to check how well the formula we found for the denominator holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Var(R_i):0.5\n",
      "Expected Numerator Value 20.0\n",
      "True Var(R_i):0.500263758566\n",
      "True Denominator Value:20.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAACQCAYAAADupNeuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMTYCxhhTYmwEjDGmxPw/euSRDLcnUiUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1256f42e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "n = 10 #trials\n",
    "s = 20 #stimuli\n",
    "n_exps = 100000 #number simulations\n",
    "sigma = np.array([5,]*s) # the variance of each trial\n",
    "\n",
    "#each trial for a stimuli has the same expectation\n",
    "lambdas = np.cos(np.linspace(0, np.pi, s)) + 1 #s\n",
    "#our model is not perfect, thus its angle is pi/4 off\n",
    "model = np.cos(np.linspace(0, np.pi, s) + np.pi/4) + 1 #s\n",
    "\n",
    "#lets calculate our expectation from the formula derived above\n",
    "sigma_R = (sigma/n) #averaging trials reduces variance.\n",
    "\n",
    "# the mean of each entry in our mean stimuli response matrix is the signal variation\n",
    "mu_cross = (np.expand_dims(lambdas, 0)*np.expand_dims(lambdas, 1))\n",
    "mu_sqrd_sum = np.sum(mu_cross) - np.trace(mu_cross)\n",
    "mu_var = ((s-1)/s)*np.sum(lambdas**2) - (1/s)*mu_sqrd_sum\n",
    "\n",
    "#the noise variance which is independent of the mean variance is added to this\n",
    "noise_var = ((s-1)/s)*np.sum(sigma_R)\n",
    "expectation = mu_var + noise_var\n",
    "\n",
    "print('Expected Var(R_i):' + str(np.mean(sigma_R)))\n",
    "print('Expected Numerator Value ' + str(np.mean(expectation)))\n",
    "\n",
    "#r = np.random.poisson(lambdas, size=(n_exps, n, s)) # nx n s\n",
    "r = np.random.normal(loc=lambdas, scale=np.sqrt(sigma), size=(n_exps, n, s)) # nx n s\n",
    "R = r.mean(1) # nx s\n",
    "print('True Var(R_i):' + str(np.mean(np.var(R, 0, ddof=1))))\n",
    "R_ms = R - R.mean(1, keepdims=True)# nx s\n",
    "var = np.sum(R_ms**2, 1)\n",
    "print('True Denominator Value:' + str(np.round(np.mean(var),2)))\n",
    "ax = plt.subplot(211)\n",
    "_ = plt.hist(var, bins=200)\n",
    "_ = plt.title('Distribution of Denominator Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Our derived formula is in good agreement with the simulation. I believe this is a chi-squared distribution as in this case it is a sum of squared normal distributions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Fraction Variance Explained: 0.83\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNji4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125bfe320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now lets try out the correction. \n",
    "sighat = np.var(r, axis=1, ddof=1)/n # nx s\n",
    "correction = np.sum(sighat,1)*((s-1)/s)\n",
    "\n",
    "model -= model.mean(0)\n",
    "error = np.linalg.lstsq(np.expand_dims(model,1), R_ms.T)[1] # nx\n",
    "\n",
    "corrected_error = error - correction\n",
    "est_true_expl_var = 1-(corrected_error/(var))\n",
    "#est_true_expl_var[est_true_expl_var>1] = 1\n",
    "est_true_expl_var_w_noise = 1-(error/var)\n",
    "ax = plt.subplot(211)\n",
    "plt.hist(est_true_expl_var_w_noise, range=[0,2], bins=200)\n",
    "plt.title('Frac Var W/ Noise:' + str(np.round(np.mean(est_true_expl_var_w_noise),2)))\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "plt.hist(est_true_expl_var, range=[0,2], bins=200)\n",
    "plt.title('Frac Var Corrected: '+ str(np.round(np.mean(est_true_expl_var),2)))\n",
    "plt.tight_layout()\n",
    "\n",
    "print('True Fraction Variance Explained: ' + str(np.round(np.corrcoef(model, lambdas)[0,1]**2, 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corrected faction of variance tends to on average be much higher than the true fraction of variance. Geometrically whats going on is that by subtracting the SE noise variance from the error effectively shifts the response vector directly towards the model vector. This correction essentially assumes that the noise variance pushed our vector directly away from the model vector. This is unlikely. \n",
    "\n",
    "\n",
    "Essentially we have some expected response vector and we want to know its angle with the model. Unfortunately we only have some samples from the distribution around this response vector. Visually if we are in 3-d our distribution around the expected vector is something spheroid, we can imagine nested cones around the model vector that describe directions with the same angle to the model vector. If we imagine the cone along which our expectation vector lies, the way in which it intersects our spheroid distribution makes it such that there is more probability mass with a greater angle than expectation than a smaller angle. This is why correlation tends to decrease with noise. To make a correction we need to integrate along these cones across the distribution of response vectors, to get the likelihood of any angle, then add the difference between this angle and the expected angle to the angle between a sampled response vector and the model vector. Than in expectation that angle will be the true angle.\n",
    "\n",
    "\n",
    "Unfortunately we do not know the expected angle nor do I know how to perform this integration. The only way I can think of to continue in this direction is to assume a distributional form of our responses (Poisson) perform a max-likelihood fit then in simulation determine the expected value (might be equivalent to the sample mean?) and the distribution of correlations. With these two we can then calculate a correction. \n",
    "While I could validate this method in simulation, it would be nice if we could think of a way to validate it on data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Fraction Variance Explained: 0.84\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLqDMzKwruYAyM7Ou5ALKzMy60v8Hza8VGJzWlGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fd72470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10 #trials\n",
    "s = 80 #stimuli\n",
    "n_exps = 100 #number experiments\n",
    "n_s = 101 # number boot strap simulations\n",
    "#each trial for a stimuli has the same expectation\n",
    "lambdas = np.cos(np.linspace(0, np.pi, s)) + 10 #s\n",
    "#our model is not perfect, thus its angle is pi/4 off\n",
    "model = np.cos(np.linspace(0, np.pi, s) + np.pi/4) + 10 #s\n",
    "\n",
    "#simulate n_exps\n",
    "r = np.random.poisson(lambdas, size=(n_exps, n, s)) # nx n s\n",
    "#now get the mean of the trials\n",
    "R = r.mean(1) # nx s\n",
    "\n",
    "#get the correlations for each of these trials. We are trying to correct this.\n",
    "R_ms = R - R.mean(1, keepdims=True)# nx s\n",
    "model_ms = model - np.mean(model);\n",
    "model_ms /= np.linalg.norm(model_ms)\n",
    "exp_cor = np.dot(R_ms/np.linalg.norm(R_ms, keepdims=True, axis=1), \n",
    "                 np.expand_dims(model_ms, 1))#nx 1\n",
    "\n",
    "#now using the means of each stimuli get a simulation of experiments\n",
    "r_est = np.array([np.random.poisson(an_R, size=(n_s, n, s)) for an_R in R])# nx ns n s\n",
    "R_est = r_est.mean(2) #nx ns s\n",
    "R_est_ms =  R_est - R_est.mean(2, keepdims=True) #nx ns s\n",
    "sim_cor = np.array([np.dot(an_R_est_ms/np.linalg.norm(an_R_est_ms, keepdims=True, axis=1),\n",
    "                 np.expand_dims(model_ms, 1)) \n",
    "                    for an_R_est_ms in R_est_ms]) #nx ns\n",
    "\n",
    "sim_cor_mn = sim_cor.mean(1)\n",
    "correction_cor = (exp_cor + exp_cor - sim_cor_mn)\n",
    "\n",
    "ax = plt.subplot(311)\n",
    "plt.hist(exp_cor**2, range=[0,2], bins=200)\n",
    "plt.title('Frac Var Exp: '+ str(np.round(np.mean(exp_cor**2),2)))\n",
    "\n",
    "ax = plt.subplot(312)\n",
    "plt.hist(sim_cor_mn**2, range=[0,2], bins=200)\n",
    "plt.title('Frac Var Sim: '+ str(np.round(np.mean(sim_cor_mn**2),2)))\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.subplot(313)\n",
    "plt.hist(correction_cor**2, range=[0,2], bins=200)\n",
    "plt.title('Frac Var Corrected: '+ str(np.round(np.mean(correction_cor**2),2)))\n",
    "print('True Fraction Variance Explained: ' + \n",
    "      str(np.round(np.corrcoef(model, lambdas)[0,1]**2, 2)))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem the proposed method does not work too well. The problem is that we are calculating our shift in correlation based on an estimate of the expected vector. In high dimensions this estimate vector has a much larger angle with the model vector than the true vector. Thus our correction is being calculated around a vector quite different than the true one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets step back and think about what we are trying to do. We know that for some distribution around an expected vector sampling from this distribution will give us a smaller correlation value. Looking at variability across trials gives us a sense for what this distribution is. It then remains to be seen what center of this distribution would make the measured correlation value likely.\n",
    "\n",
    "$$P(\\theta \\ | \\ r_{ij}, \\ \\hat{\\theta}, \\ \\hat{f})$$\n",
    "\n",
    "That is given our responses $r_{ij}$ the angle between their mean and our model vector ($\\hat{\\theta}$) and the assumed parameterized distribution from which $r_{ij}$ was drawn, what is the likelihood of the angle between our responses in expectation and the model vector ($\\theta$).\n",
    "\n",
    "We can attempt to solve this problem using a brute force search and Monte Carlo estimation of likelihood. We first construct a vector that has a $\\theta$ we want to know the likelihood of. This could be done by titrating phase randomization of the model vector to the correct $\\theta$ or adding in our model vector to our response vector till the correct ($\\theta$).\n",
    "We then place our estimate of the distribution around this vector, sample correlations from it, to build up a distribution of correlations then read off the likelihood of our observed $\\hat{\\theta}$.\n",
    "One of the many issues with this method is it assumes the shape of the distribution is independent of its position. While this would be true of a gaussian, it would not be true of a Poisson. Other issues include that it is computationally expensive and only intuitiviely justified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Simulate net units as having neural variability</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our question is whether AlexNet units can serve as an image computable model of APC tuning. A point of reference is the APC tuning of V4 neurons, these are proof that these computations can be approximated to some degree on images. In principal then if AlexNet can serve as a model of V4 its units should at least match or exceed this degree in a neurons quality as an image computable model of APC. \n",
    "\n",
    "\n",
    "\n",
    "In making a comparions between neurons and units, we want to ask if these units had the variability of neurons what kind of fits would we expect or conversely if our neurons had no variability what kind of fit would we expect. We know that variability will nearly always decrease the quality of fits. So if a neuron and a unit get the same fit to a model, we know that in expecation the neuron's fit is better and AlexNet does not actually match. \n",
    "\n",
    "One way to make the comparison is include neural like variability in AlexNet. If we do this conservatively (add minimal noise) and AlexNet drops below V4 we can with confidence state that AlexNet is not as good of an image computable model of APC as V4. If we do this liberally and AlexNet remains above V4 we can state with confidence that AlexNet is as good or better as an image computable model of APC.\n",
    "\n",
    "We now need to determine a method by which we can convincingly add conservative to liberal amounts of noise. \n",
    "\n",
    "For a conservative estimate we can take the highest SNR found in a neural experiment and pull from a distribution centered around the response of AlexNet units that matches this SNR. The mean and variance which define the SNR only mildly constrain the shape of this distribution. While ideally we would match the distribution of neural variability (Poisson, Negative Binomial) the nature of the responses in AlexNet make this dubious. Responses in AlexNet can be both positive and negative, whereas neural responses are positive. Responses in AlexNet are continuous whereas neural responses are discrete. Finally the scale of responses in AlexNet is arbitrary, but a Poisson distribution relates variance to the scale of responses. So for example many units have responses less than 1 which modeled as a Poisson distribution would result in a simulation in which most responses are 0.\n",
    "\n",
    "Because our experimental results are the average of several trials and the sum of independent trials converges on a Gaussian, it is not unreasonable to choose the shape of our distribution to be Gaussian and avoid many of the aformentioned problems.\n",
    "\n",
    "\n",
    "<h5>SNR</h5>\n",
    "$$\\frac{\\sigma^2_{signal}}{\\sigma^2_{noise}}$$\n",
    "\n",
    "Previously we determined the variance of our experiment could be decomposed as such:\n",
    "\n",
    "$$Var = \\frac{s-1}{s}\\sum_i^s{\\sigma_i^2} + \\frac{s-1}{s}\\sum_i^s{\\mu_i^2}  - \\frac{1}{s} \\sum_i^s{(\\mu_i \\sum_{g \\neq i}^{s-1}{\\mu_g})} $$\n",
    "\n",
    "plugging this into the formula above:\n",
    "\n",
    "$$\\frac{\\sigma^2_{signal}}{\\sigma^2_{noise}} = \\frac {\\frac{s-1}{s}\\sum_i^s{\\mu_i^2}  - \\frac{1}{s} \\sum_i^s{(\\mu_i \\sum_{g \\neq i}^{s-1}{\\mu_g})}}{\\frac{s-1}{s}\\sum_i^s{\\sigma_i^2}} $$\n",
    "\n",
    "I'm pretty sure  that numerator reduces to sample variance. We then substitute estimates into these values.\n",
    "$$\\mu_i = R_i = \\frac{1}{n}\\sum_j^n{r_{ij}}$$\n",
    "\n",
    "$$\\sigma_i^2 = \\frac{1}{n^2-n} \\sum_j^n{(r_{ij} - \\frac{1}{n}\\sum_j^n{r_{ij}})^2} $$\n",
    "$$\\sigma^2_{noise} = \\sum{\\sigma_i^2}$$\n",
    "\n",
    "Now with our SNR estimate we need to take a given response from AlexNet and determines its distribution to match this SNR. We assume the mean of the distribution are the actual responses thus we know the numerator of the SNR, all that remains is to solve for the scaling of the denominator:\n",
    "$$ SNR_{neuron} = \\frac{\\sigma^2_{signal}}{ a \\sigma^2_{noise}}$$\n",
    "\n",
    "$$\\frac{\\sigma^2_{noise} \\ SNR_{neuron}}{\\sigma^2_{signal}}  = a $$\n",
    "\n",
    "where $a$ is the scaling of $\\sigma^2_{noise}$ a sum of $\\sigma_i^2$.\n",
    "\n",
    "Thus the form of our AlexNet 'neural-like' distribution will be $N(\\mu_i, \\  a \\ \\sigma_i)$. We have still not determined what each $\\sigma_i$ should be. One option would be to make them homoscedastic (i.e. all equal) another would be to make them heteroscedastic (i.e. not equal).\n",
    "Heteroscedascity would be more neural-like given neural responses tend to increase their variance with a higher firing rate, and neurons tend to have higher responses to some stimuli than others. Given that higher responses tend to have more leverage on a least squares fit their variance would be more damaging to a model fit. It might be reasonable then to make the comparison more fair by scaling the variance to the means. \n",
    "\n",
    "$$\\sigma_{i \\ scaled}^2 = b \\ \\mu_i $$\n",
    "\n",
    "where in this case $\\mu_i$ is the actual response of AlexNet. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#heteroscedsacity and correlation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "n = 10 #trials\n",
    "s = 20 #stimuli\n",
    "n_exps = 100000 #number simulations\n",
    "sigma = np.array([5,]*s) # the variance of each trial\n",
    "\n",
    "#each trial for a stimuli has the same expectation\n",
    "lambdas = np.cos(np.linspace(0, np.pi, s)) + 1 #s\n",
    "#our model is not perfect, thus its angle is pi/4 off\n",
    "model = np.cos(np.linspace(0, np.pi, s) + np.pi/4) + 1 #s\n",
    "\n",
    "print('Expected Var(R_i):' + str(np.mean(sigma_R)))\n",
    "print('Expected Numerator Value ' + str(np.mean(expectation)))\n",
    "\n",
    "#r = np.random.poisson(lambdas, size=(n_exps, n, s)) # nx n s\n",
    "r = np.random.normal(loc=lambdas, scale=np.sqrt(sigma), size=(n_exps, s)) # nx n s\n",
    "R = r.mean(1) # nx s\n",
    "print('True Var(R_i):' + str(np.mean(np.var(R, 0, ddof=1))))\n",
    "R_ms = R - R.mean(1, keepdims=True)# nx s\n",
    "var = np.sum(R_ms**2, 1)\n",
    "print('True Denominator Value:' + str(np.round(np.mean(var),2)))\n",
    "ax = plt.subplot(211)\n",
    "_ = plt.hist(var, bins=200)\n",
    "_ = plt.title('Distribution of Denominator Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
